{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "afbb588f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pypose as pp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21ff76e3",
   "metadata": {},
   "source": [
    "# 1. Intialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "77de72ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a: so3Type Group:\n",
      "tensor([[-2.8550,  0.9274,  1.9018],\n",
      "        [-0.3818, -1.8837,  0.5071]]) \n",
      "x.shape: torch.Size([2, 1, 7]) \n",
      "x.gshape: torch.Size([2, 1])\n",
      "SE3Type Group:\n",
      "tensor([[0., 0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 0., 1.]])\n",
      "se3Type Group:\n",
      "tensor([[[ 0.7216,  0.3705,  0.7914,  0.5841, -0.8191, -0.2729],\n",
      "         [-0.7464, -0.3715,  0.9468, -1.5123,  0.0142, -0.0490]],\n",
      "\n",
      "        [[-0.3291, -0.7238, -0.3968, -0.0429,  0.1484,  0.8858],\n",
      "         [-0.9697,  0.9750,  1.4834, -0.2072,  1.8970, -1.1792]]])\n"
     ]
    }
   ],
   "source": [
    "a = pp.so3(torch.randn(2,3))\n",
    "x = pp.identity_SE3(2,1)\n",
    "y = pp.randn_se3(2,2)\n",
    "print('a:', a, '\\nx.shape:', x.shape, '\\nx.gshape:', x.gshape)\n",
    "print(x.gview(2))\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cff3249",
   "metadata": {},
   "source": [
    "### All arguments in PyTorch are supported"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3003efc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(SO3Type Group:\n",
       " tensor([[ 0.0534,  0.7060, -0.2022,  0.6767],\n",
       "         [-0.3990, -0.8116, -0.0492,  0.4239],\n",
       "         [ 0.0213,  0.3176, -0.2628,  0.9108]], device='cuda:0',\n",
       "        dtype=torch.float64, requires_grad=True),\n",
       " SO3Type Group:\n",
       " tensor([[ 0.0534,  0.7060, -0.2022,  0.6767],\n",
       "         [-0.3990, -0.8116, -0.0492,  0.4239],\n",
       "         [ 0.0213,  0.3176, -0.2628,  0.9108]], device='cuda:0',\n",
       "        grad_fn=<AliasBackward0>))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = pp.randn_SO3(3, device=\"cuda:0\", dtype=torch.double, requires_grad=True)\n",
    "b = pp.identity_like(a, device=\"cpu\")\n",
    "a, b\n",
    "t = a.float()\n",
    "a, t"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "minute-archives",
   "metadata": {},
   "source": [
    "# 2. Slicing and Shaping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "welsh-assembly",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A: torch.Size([2, 2])\n",
      "B: torch.Size([2, 1])\n",
      "C: torch.Size([2, 3])\n",
      "D: torch.Size([3])\n",
      "E: torch.Size([2, 1])\n",
      "F: torch.Size([2, 2])\n"
     ]
    }
   ],
   "source": [
    "A = pp.randn_SO3(2,2)\n",
    "B = pp.randn_SO3(2,1)\n",
    "C = torch.cat([A,B], dim=1)         # Tensor cat\n",
    "C[0,1] = pp.randn_SO3(1)            # Slicing set\n",
    "D = C[1,:].Log()                    # Slicing get\n",
    "E, F = torch.split(C, [1,2], dim=1) # Tensor split\n",
    "print('A:', A.gshape)\n",
    "print('B:', B.gshape)\n",
    "print('C:', C.gshape)\n",
    "print('D:', D.gshape)\n",
    "print('E:', E.gshape)\n",
    "print('F:', F.gshape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7ea61f8",
   "metadata": {},
   "source": [
    "# 3. Basic Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b6927dac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "se3Type Group:\n",
       "tensor([[[-0.7216, -0.3705, -0.7914, -0.5841,  0.8191,  0.2729],\n",
       "         [ 0.7464,  0.3715, -0.9468,  1.5123, -0.0142,  0.0490]],\n",
       "\n",
       "        [[ 0.3291,  0.7238,  0.3968,  0.0429, -0.1484, -0.8858],\n",
       "         [ 0.9697, -0.9750, -1.4834,  0.2072, -1.8970,  1.1792]]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(x * y.Exp()).Inv().Log()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f94d83b4",
   "metadata": {},
   "source": [
    "# 4. Adjoint Transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "23028575",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(True)\n"
     ]
    }
   ],
   "source": [
    "X = pp.randn_Sim3(6, dtype=torch.double)\n",
    "a = pp.randn_sim3(6, dtype=torch.double)\n",
    "b = X.AdjT(a)\n",
    "print((X * b.Exp() - a.Exp() * X).abs().mean() < 1e-7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c8a2cca5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(True)\n"
     ]
    }
   ],
   "source": [
    "X = pp.randn_SE3(8)\n",
    "a = pp.randn_se3(8)\n",
    "b = X.Adj(a)\n",
    "print((b.Exp() * X - X * a.Exp()).abs().mean() < 1e-7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fef005df",
   "metadata": {},
   "source": [
    "# 5. Grdients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "331ff3f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.1452, device='cuda:0', grad_fn=<SumBackward0>),\n",
       " tensor([[-0.1873, -0.3202, -0.0706],\n",
       "         [-0.1536,  0.3928, -0.4324],\n",
       "         [-0.1768, -0.0231, -0.2022]], device='cuda:0'),\n",
       " so3Type Group:\n",
       " tensor([[-0.0937, -0.1602, -0.0353],\n",
       "         [-0.0768,  0.1965, -0.2164],\n",
       "         [-0.0884, -0.0116, -0.1011]], device='cuda:0', requires_grad=True),\n",
       " so3Type Group:\n",
       " tensor([[-0.0937, -0.1602, -0.0353],\n",
       "         [-0.0768,  0.1965, -0.2164],\n",
       "         [-0.0884, -0.0116, -0.1011]], device='cuda:0'))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = pp.randn_so3(3, sigma=0.1, requires_grad=True, device=\"cuda\")\n",
    "assert x.is_leaf\n",
    "loss = (x.Exp().Log()**2).sin().sum() # Just test, No physical meaning\n",
    "loss.backward()\n",
    "y = x.detach()\n",
    "loss, x.grad, x, y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff7c91bb",
   "metadata": {},
   "source": [
    "# 6. Test a Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0bd984bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before Optimization:\n",
      " so3Type Group:\n",
      "Parameter containing:\n",
      "tensor([[-2.1001, -1.2749,  0.3482],\n",
      "        [-1.4677, -0.8262,  0.6530],\n",
      "        [-1.4498, -0.1315,  0.2014],\n",
      "        [ 0.9867, -0.3606,  0.7121]], device='cuda:0', requires_grad=True)\n",
      "tensor(6.6041, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(7.3226, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(6.6431, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(6.5915, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(7.0237, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "Parameter: 12\n",
      "After Optimization:\n",
      " so3Type Group:\n",
      "Parameter containing:\n",
      "tensor([[-0.7197, -0.5055,  0.6865],\n",
      "        [ 0.2213,  0.1932,  0.5925],\n",
      "        [-0.9299, -0.3800, -0.2991],\n",
      "        [ 0.1170, -0.1062,  0.5903]], device='cuda:0', requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "from torch import nn\n",
    "\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "class TestNet(nn.Module):\n",
    "    def __init__(self, n):\n",
    "        super().__init__()\n",
    "        self.weight = pp.Parameter(pp.randn_so3(n))\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.weight.Exp() * x\n",
    "\n",
    "\n",
    "n,epoch = 4, 5\n",
    "net = TestNet(n).cuda()\n",
    "\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr = 0.2, momentum=0.9)\n",
    "scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[2,4], gamma=0.5)\n",
    "\n",
    "print(\"Before Optimization:\\n\", net.weight)\n",
    "for i in range(epoch):\n",
    "    optimizer.zero_grad()\n",
    "    inputs = pp.randn_SO3(n).cuda()\n",
    "    outputs = net(inputs)\n",
    "    loss = outputs.abs().sum()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    scheduler.step()\n",
    "    print(loss)\n",
    "\n",
    "print(\"Parameter:\", count_parameters(net))\n",
    "print(\"After Optimization:\\n\", net.weight)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
