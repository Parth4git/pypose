import torch, pypose as pp



class TestLQR:

    def test_lqr_linear(self, device='cpu'):

        # The reference data
        x_ref = torch.tensor([
            [[ 1.500000000e+00, -3.4000000357e-01, -2.1800000667e+00,  5.4000002145e-01],
             [ 7.082195281e-01, -3.8224798440e-01,  1.2187952995e+00, -2.8270375728e-01],
             [ 1.063972711e+00, -1.2412147521e+00, -6.9346541166e-01, -1.5017517805e+00],
             [ 7.438300251e-01, -1.3315110206e+00, -2.4556130170e-01, -4.0074110031e-02],
             [ 8.388060331e-02, -2.1701562404e+00, -1.0819011926e-01, -1.8782937526e-01],
             [-5.301788449e-02, -2.1380202770e+00, 1.54667758941+00,  -1.1694585084e+00]],
            [[-1.049999952e+00, -1.3600000143e+00,  4.3000000715e-01,  8.0000001192e-01],
             [ 6.865886449e-01, -2.7504599094e+00, -1.4547507762e+00, -1.2115331888e+00],
             [ 2.044222593e+00, -2.2286529541e+00, -2.0166194438e+00, -2.4150242805e+00],
             [ 3.183010101e+00,  1.3153430223e+00, -2.0461211204e+00, -1.9447833299e+00],
             [ 2.406511783e+00, -6.8622183799e-01,  4.3126922845e-01,  1.2989995479e+00],
             [ 5.505656242e+00, -5.6250834465e-01,  4.0067559480e-01,  2.6752333641e+00]]],
            device=device)

        u_ref = torch.tensor([
            [[ 8.0248779058456421e-01,  2.4977316856384277e+00,  1.5325248241424561e+00],
             [ 1.0684574842453003e+00,  2.7619558572769165e-01,  1.4526504278182983e-01],
             [-1.1169517040252686e+00,  1.0167986154556274e-01, -1.6897654533386230e-01],
             [ 5.0239115953445435e-02,  8.5282796621322632e-01, -3.1150743365287781e-01],
             [-2.0000000298023224e-01,  1.3200000524520874e+00,  6.0000002384185791e-01]],
            [[ 1.4756069183349609e+00, -1.2672777175903320e+00,  3.1231970787048340e+00],
             [ 1.4230382442474365e-01, -8.6675214767456055e-01,  2.0238971710205078e+00],
             [ 4.8898696899414062e-02,  4.5528823137283325e-01,  8.2487571239471436e-01],
             [ 3.2995104789733887e-02, -1.0528842210769653e+00,  1.7456316947937012e-01],
             [ 2.7000001072883606e-01, -1.2999999523162842e-01, -8.6000001430511475e-01]]],
            device=device)

        n_batch, T = 2, 5
        n_state, n_ctrl = 4, 3

        Q = torch.tile(torch.eye(n_state + n_ctrl, device=device), (n_batch, T, 1, 1))
        p = torch.tensor([
            [[-1.00, -0.68, -0.35, -1.42,  0.23, -1.73, -0.54],
             [-0.02, -1.13, -1.40,  0.13, -0.67, -0.92,  0.97],
             [-0.77,  0.59,  1.49,  0.54,  0.45,  0.62,  1.83],
             [-0.95, -0.80,  0.36, -0.81, -0.03,  0.39,  0.42],
             [ 1.52,  0.01,  0.36,  0.68,  0.20, -1.32, -0.60]],
            [[ 1.37,  0.38,  0.75,  1.55,  0.89,  0.82, -0.13],
             [ 0.68, -0.08,  0.81,  0.10, -0.05,  2.01, -0.64],
             [ 0.01,  0.68,  0.97, -1.15, -1.02, -0.87,  0.43],
             [-1.79, -1.08,  0.30,  0.32, -0.27,  1.36,  0.21],
             [ 0.20, -0.68, -2.73, -0.52, -0.27,  0.13,  0.86]]],
            device=device)
        A = torch.tensor([
            [[ 1.05, -0.19,  0.17,  0.31],
             [-0.01,  0.93,  0.04, -0.05],
             [ 0.02,  0.48,  1.26, -0.05],
             [ 0.07,  0.50, -0.53,  1.48]],
            [[ 1.54, -0.62,  0.78,  0.31],
             [-0.01,  0.01,  0.04, -0.77],
             [ 0.97,  0.48,  1.56, -0.28],
             [ 0.29,  0.88, -0.79,  1.48]]], device=device)
        B = torch.tensor([
            [[ 0.01, -0.99,  0.97], [-0.44, -0.10,  0.80],
             [-1.71,  2.33,  0.41], [-1.13, -0.93, -0.08]],
            [[ 0.04,  0.25,  0.12], [ 1.76,  1.42, -0.78],
             [-1.28, -0.21,  0.75], [-0.52,  0.64, -0.05]]], device=device)
        C = torch.tile(torch.eye(n_state, device=device), (n_batch, 1, 1))
        D = torch.zeros(n_batch, n_state, n_ctrl, device=device)
        c1 = torch.tensor([[ 0.25, -0.56, -0.95,  1.18],
                           [ 0.76, -0.51, -0.95,  1.18]], device=device)
        c2 = torch.zeros(n_batch, n_state, device=device)
        x_init = torch.tensor([[ 1.50, -0.34, -2.18,  0.54],
                               [-1.05, -1.36,  0.43,  0.80]], device=device)

        lti = pp.module.LTI(A, B, C, D, c1, c2).to(device)
        LQR = pp.module.LQR(lti, Q, p, T).to(device)
        x, u, cost = LQR(x_init)

        torch.testing.assert_close(x_ref, x, rtol=1e-5, atol=1e-3)
        torch.testing.assert_close(u_ref, u, atol=1e-5, rtol=1e-3)


    def test_lqr_ltv(self, device='cpu'):

        # The reference data
        x_ref = torch.tensor([
            [[ 1.500000000e+00, -3.400000036e-01, -2.180000067e+00,  5.400000215e-01],
             [ 2.377519608e+00,  5.375196934e-01, -1.302480459e+00,  1.417519689e+00],
             [ 3.990919352e+00,  3.109195828e-01, -3.369080782e+00,  2.070919514e+00],
             [ 1.044221497e+01, -5.977841020e-01, -1.163778496e+01,  4.682215691e+00],
             [ 3.979527664e+01, -4.364719391e+00, -4.852472305e+01,  1.675527954e+01],
             [ 2.091763763e+02, -1.162359715e+01, -2.324236145e+02,  9.397639465e+01]],
            [[-1.049999952e+00, -1.360000014e+00,  4.300000072e-01,  8.000000119e-01],
             [-1.002597809e-02, -3.200260401e-01,  1.469974041e+00,  1.839973927e+00],
             [-7.595360279e-01, -1.379536152e+00,  2.200464010e+00,  2.940463781e+00],
             [-3.807788372e+00, -5.667788506e+00,  5.072211266e+00,  7.292210579e+00],
             [-1.720472145e+01, -2.464472198e+01,  1.831527710e+01,  2.719527435e+01],
             [-7.582360840e+01, -1.130236130e+02,  1.017763824e+02,  1.461763763e+02]]],
            device=device)

        u_ref = torch.tensor([
            [[-6.1749368906021118e-01, 1.3425066471099854e+00,  1.5250672399997711e-01],
             [-1.0373570919036865e+00, 9.2264837026596069e-01, -2.6735118031501770e-01],
             [-1.0800650119781494e+00, 8.7994140386581421e-01, -3.1005731225013733e-01],
             [-1.0744671821594238e+00, 8.8553500175476074e-01, -3.0446350574493408e-01],
             [-2.3000000417232513e-01, 1.7300000190734863e+00,  5.4000002145767212e-01]],
            [[-5.6334143877029419e-01, 1.3966575860977173e+00,  2.0665787160396576e-01],
             [-1.0332505702972412e+00, 9.2675399780273438e-01, -2.6324546337127686e-01],
             [-1.0799123048782349e+00, 8.8009214401245117e-01, -3.0990654230117798e-01],
             [-1.0744727849960327e+00, 8.8554155826568604e-01, -3.0446064472198486e-01],
             [-2.3000000417232513e-01, 1.7300000190734863e+00,  5.4000002145767212e-01]]],
            device=device)

        n_batch, T = 2, 5
        n_state, n_ctrl = 4, 3

        Q = torch.tile(torch.eye(n_state + n_ctrl, device=device), (n_batch, 1, 1))
        p = torch.tensor([[-1.00, -0.68, -0.35, -1.42, 0.23, -1.73, -0.54],
                          [-1.00, -0.68, -0.35, -1.42, 0.23, -1.73, -0.54]], device=device)
        rt = torch.arange(1, T+1).view(T, 1, 1)
        A = rt * torch.tile(torch.eye(n_state, device=device), (n_batch, T, 1, 1))
        B = rt * torch.ones(n_batch, T, n_state, n_ctrl, device=device)
        C = torch.tile(torch.eye(n_state, device=device), (n_batch, T, 1, 1))
        D = torch.zeros(n_batch, T, n_state, n_ctrl, device=device)
        x_init = torch.tensor([[ 1.50, -0.34, -2.18,  0.54],
                               [-1.05, -1.36,  0.43,  0.80]], device=device)

        class MyLTV(pp.module.LTV):

            def __init__(self, A, B, C, D):
                super().__init__(A, B, C, D)

            @property
            def A(self):
                return self._A[...,self._t,:,:]

            @property
            def B(self):
                return self._B[...,self._t,:,:]

            @property
            def C(self):
                return self._C[...,self._t,:,:]

            @property
            def D(self):
                return self._D[...,self._t,:,:]

        ltv = MyLTV(A, B, C, D).to(device)
        lqr  = pp.module.LQR(ltv, Q, p, T).to(device)
        x, u, cost = lqr(x_init)

        torch.testing.assert_close(x_ref, x, atol=1e-5, rtol=1e-3)
        torch.testing.assert_close(u_ref, u, atol=1e-5, rtol=1e-3)


if __name__ == '__main__':
    test = TestLQR()
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    test.test_lqr_linear(device)
    test.test_lqr_ltv(device)
